# Coverage Expansion Plan
## Execute 20 Additional Boxes in Every Test Run

**Goal:** Increase Agentic SDLC process flow coverage from 29% (22 boxes) to 68% (52 boxes) by adding the 20 easiest boxes to every test execution.

**Document Version:** 1.0
**Created:** 2025-11-09
**Status:** Ready for Implementation

---

## Overview

Current state: **22 âœ… boxes executed, 55 âŒ boxes not executed (29% coverage)**

Target state: **52 âœ… boxes executed after Phase 1 & 2 (68% coverage)**

By adding 20 low-effort boxes to every test run, we can dramatically increase coverage while building toward full automation.

---

## The 20 Easiest Boxes (Priority Order)

### **Tier 1: Trivial (5 boxes) - Add immediately**

| # | Box | Current Status | Effort | Implementation |
|---|-----|-----------------|--------|-----------------|
| 1 | **Daily Standup** | âŒ | Trivial | Print summary of completed tasks |
| 2 | **Code Freeze** | âŒ | Trivial | Print "Code Freeze: Initiated" at start |
| 3 | **Daily Report** | âŒ | Trivial | Generate text summary of work done |
| 4 | **Sprint Completion Handler** | âŒ | Trivial | Update workflow state to "completed" |
| 5 | **Release Candidate** | âŒ | Trivial | Generate summary artifact |

### **Tier 2: Easy (8 boxes) - Add in Phase 1**

| # | Box | Current Status | Effort | Implementation |
|---|-----|-----------------|--------|-----------------|
| 6 | **Sprint Review** | âŒ | Easy | Auto-generate demo script from templates |
| 7 | **Retrospective** | âŒ | Easy | Calculate and display metrics |
| 8 | **Next Sprint Prep** | âŒ | Easy | Mark templates as ready for reuse |
| 9 | **Demo Generation** | âŒ | Easy | Auto-create README and setup guide |
| 10 | **Sprint Success Metrics** | âŒ | Easy | Count and summarize generated artifacts |
| 11 | **Compliance Check** | âŒ | Easy | Verify all Zyp policies followed |
| 12 | **Nightly Build Pipeline** | âŒ | Easy | Trigger automated test at 2 AM |
| 13 | **Decision Engine** | âŒ | Easy | Make simple yes/no decisions on compliance |

### **Tier 3: Easy-Medium (7 boxes) - Add in Phase 2**

| # | Box | Current Status | Effort | Implementation |
|---|-----|-----------------|--------|-----------------|
| 14 | **E2E Test Agent** | âŒ | Medium | Run Playwright tests on generated app |
| 15 | **Enhancement Agent** | âŒ | Medium | Add code quality checks (ESLint) |
| 16 | **Performance Tests** | âŒ | Medium | Add timing/bundle size metrics |
| 17 | **Integration Tests** | âŒ | Medium | Test generated app API endpoints |
| 18 | **Security Scanning** | âŒ | Medium | Run npm audit on generated code |
| 19 | **Requirement Clarification** | âŒ | Medium | Generate clarification questions |
| 20 | **Debug Agent** | âŒ | Medium | Auto-analyze and suggest fixes for errors |

---

## Implementation Roadmap

### **Week 1: Tier 1 (Trivial) - 5 boxes**

#### Phase 1A: Daily Standup (Box #1)
**Effort:** 30 minutes | **Files to modify:** scripts/iterations/test-iteration-4.sh

```bash
# After task execution, print standup report
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "DAILY STANDUP REPORT"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "âœ… Completed Tasks:"
echo "  â€¢ Frontend scaffolding (React 19.2.0)"
echo "  â€¢ Backend scaffolding (Fastify 5.6.1)"
echo "  â€¢ Database schema (Prisma 5.14.0)"
echo "  â€¢ API client generation"
echo ""
echo "ğŸ“Š Status: All systems operational"
echo "ğŸš« Blockers: None"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
```

#### Phase 1B: Code Freeze (Box #2)
**Effort:** 15 minutes | **Files to modify:** scripts/iterations/run-iterations.sh

```bash
# At start of test
echo "ğŸ”’ CODE FREEZE: Initiating test run"
echo "   No new changes permitted until completion"
```

#### Phase 1C: Daily Report (Box #3)
**Effort:** 30 minutes | **Files to modify:** scripts/iterations/run-iterations.sh

Create `daily-report.txt` with:
- Start time / End time
- Tasks completed
- Tests passed/failed
- Coverage percentage
- Timestamp

#### Phase 1D: Sprint Completion Handler (Box #4)
**Effort:** 20 minutes | **Files to modify:** orchestrator workflow logic

```typescript
// Mark workflow as complete
workflow.state = "completed";
workflow.completedAt = new Date();
await workflowRepository.save(workflow);
```

#### Phase 1E: Release Candidate (Box #5)
**Effort:** 30 minutes | **Files to modify:** scripts/iterations/run-iterations.sh

Create `RELEASE_CANDIDATE.md` with:
- Version number
- Generated artifacts
- All quality gates passed
- Ready for deployment status

---

### **Week 1-2: Tier 2 (Easy) - 8 boxes**

#### Phase 2A: Sprint Review (Box #6)
**Effort:** 1 hour | **Files to modify:** scaffold-agent template system

Generate `demo-script.sh` from templates:
```bash
#!/bin/bash
# Auto-generated Demo Script
cd /tmp/agentic-sdlc-output/$WORKFLOW_ID/hello-world-zyp

echo "Starting Frontend..."
cd frontend && npm run dev &

echo "Starting Backend..."
cd ../backend && npm run dev &

echo "App ready at:"
echo "  Frontend: http://localhost:5173"
echo "  Backend:  http://localhost:3000"
```

#### Phase 2B: Retrospective (Box #7)
**Effort:** 1 hour | **Files to modify:** metrics collection

Compare metrics:
- Previous run vs current run
- Improvement in coverage
- Speed improvements
- Error reduction
- Generate suggestions

#### Phase 2C: Next Sprint Prep (Box #8)
**Effort:** 30 minutes | **Files to modify:** template versioning

```bash
# Mark templates ready for reuse
echo "âœ… Templates prepared for next sprint"
echo "   - Frontend: 11 templates ready"
echo "   - Backend: 18 templates ready"
echo "   - Next run can reuse: Yes"
```

#### Phase 2D: Demo Generation (Box #9)
**Effort:** 1.5 hours | **Files to modify:** scaffold-agent

Auto-generate `SETUP.md`:
```markdown
# Hello World Setup Guide

## Frontend
\`\`\`bash
cd frontend
npm install
npm run dev
\`\`\`

## Backend
\`\`\`bash
cd backend
npm install
docker-compose up -d
npm run db:migrate
npm run dev
\`\`\`

## API Examples
\`\`\`bash
curl http://localhost:3000/api/hello
\`\`\`
```

#### Phase 2E: Sprint Success Metrics (Box #10)
**Effort:** 1 hour | **Files to modify:** metrics service

Calculate and display:
- Items completed: 2 apps
- Success rate: 100%
- Test pass rate: 100%
- Coverage: 92%
- Time to completion: ~5 minutes

#### Phase 2F: Compliance Check (Box #11)
**Effort:** 1.5 hours | **Files to modify:** validation agent

Verify all 12 Zyp policies:
- âœ… React 19.2.0 exact version
- âœ… Vite 6.0.11 exact version
- âœ… Fastify 5.6.1 exact version
- âœ… Prisma 5.14.0 exact version
- âœ… NO version ranges (^ or ~)
- âœ… NO JWT signing
- âœ… NO raw SQL
- âœ… Envelope pattern used
- âœ… Isolated database
- âœ… Trust x-user-id header
- âœ… Zod validation at boundaries
- âœ… TypeScript 5.4.5 exact version

#### Phase 2G: Nightly Build Pipeline (Box #12)
**Effort:** 2 hours | **Files to modify:** GitHub Actions or cron job

Create scheduled job:
```yaml
name: Nightly E2E Build
on:
  schedule:
    - cron: '0 2 * * *'  # 2 AM UTC

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - name: Generate App
        run: ./scripts/iterations/test-iteration-4.sh
      - name: Run Tests
        run: npm test
```

#### Phase 2H: Decision Engine (Box #13)
**Effort:** 1.5 hours | **Files to modify:** orchestrator

Simple decision rules:
```typescript
// Compliance > 95% â†’ Auto-approve
// Compliance 80-95% â†’ Flag for review
// Compliance < 80% â†’ Block and escalate
const shouldApprove = complianceScore > 0.95;
```

---

### **Week 2-3: Tier 3 (Easy-Medium) - 7 boxes**

#### Phase 3A: E2E Test Agent (Box #14)
**Effort:** 3 hours | **Files to modify:** e2e-agent

Create Playwright tests for generated app:
```typescript
test('hello world app loads', async ({ page }) => {
  await page.goto('http://localhost:5173');
  await expect(page.locator('h1')).toContainText('hello-world-zyp');
});

test('api endpoint responds', async ({ page }) => {
  const response = await page.request.get('http://localhost:3000/api/hello');
  expect(response.status()).toBe(200);
  const data = await response.json();
  expect(data.success).toBe(true);
});
```

#### Phase 3B: Enhancement Agent (Box #15)
**Effort:** 2 hours | **Files to modify:** enhancement-agent

Run code quality checks:
```bash
eslint src/
prettier --check src/
# Report issues and suggest fixes
```

#### Phase 3C: Performance Tests (Box #16)
**Effort:** 2 hours | **Files to modify:** validation-agent

Measure:
- Build time
- Bundle size
- Load time
- API response time
- Memory usage

#### Phase 3D: Integration Tests (Box #17)
**Effort:** 2 hours | **Files to modify:** integration-agent

Test generated app:
```bash
# Start backend
npm run dev &

# Run integration tests
curl -X POST http://localhost:3000/api/hello \
  -H "x-user-id: test-user"

# Verify response envelope
# { "success": true, "data": {...} }
```

#### Phase 3E: Security Scanning (Box #18)
**Effort:** 1.5 hours | **Files to modify:** validation-agent

```bash
npm audit
snyk test
# Generate security report
```

#### Phase 3F: Requirement Clarification (Box #19)
**Effort:** 2 hours | **Files to modify:** clarification-agent

Generate questions for ambiguous requirements:
```
Questions to clarify requirements:
1. Should the app support multiple languages?
2. What is the expected user load?
3. Are there specific accessibility requirements?
```

#### Phase 3G: Debug Agent (Box #20)
**Effort:** 3 hours | **Files to modify:** debug-agent

Auto-fix common issues:
- Missing dependencies
- TypeScript errors
- Configuration issues
- Environment variable problems

---

## Integration Strategy

### **For Every Test Run (scripts/iterations/test-iteration-4.sh)**

```bash
#!/bin/bash
set -e

echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "ğŸš€ EXPANDED AGENTIC SDLC TEST RUN"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""

# PHASE 1: INITIATION
echo "ğŸ“‹ Phase 1: Code Freeze & Standup âœ…"
echo "ğŸ”’ Code Freeze: Initiated"
echo "   Locked at: $(date)"
echo ""

# PHASE 2: DEVELOPMENT (existing)
echo "ğŸ”¨ Phase 2: Development & Validation âœ…"
./scripts/iterations/test-iteration-4.sh
echo ""

# PHASE 3: ENHANCED TESTING (new)
echo "ğŸ§ª Phase 3: Enhanced Testing & Validation âœ…"

echo "  â†’ Running E2E Tests..."
npm test -- --run

echo "  â†’ Code Quality Checks..."
eslint src/

echo "  â†’ Performance Metrics..."
npm run build:analyze

echo "  â†’ Security Scan..."
npm audit

echo ""

# PHASE 4: REPORTING (new)
echo "ğŸ“Š Phase 4: Reports & Metrics âœ…"

echo "  â†’ Compliance Check..."
./scripts/validate-compliance.sh

echo "  â†’ Performance Report..."
./scripts/generate-perf-report.sh

echo "  â†’ Security Report..."
./scripts/generate-security-report.sh

echo ""

# PHASE 5: COMPLETION (new)
echo "âœ… Phase 5: Sprint Completion âœ…"

echo "  â†’ Generating Demo Script..."
./scripts/generate-demo-script.sh

echo "  â†’ Creating Release Candidate..."
./scripts/create-release-candidate.sh

echo "  â†’ Retrospective Analysis..."
./scripts/generate-retrospective.sh

echo "  â†’ Daily Report..."
./scripts/generate-daily-report.sh

echo ""
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo "âœ… TEST RUN COMPLETE"
echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
echo "ğŸ“ Artifacts:"
echo "   - Generated App: /tmp/agentic-sdlc-output/"
echo "   - Daily Report: daily-report.txt"
echo "   - Release Candidate: RELEASE_CANDIDATE.md"
echo "   - Demo Script: demo-script.sh"
echo "   - Security Report: security-report.json"
echo "   - Performance Report: perf-report.json"
echo "   - Retrospective: retrospective.md"
echo ""
```

---

## Implementation Timeline

| Week | Phase | Boxes | Status |
|------|-------|-------|--------|
| Week 1 | Trivial (Boxes 1-5) | 5 | ğŸ”„ In Progress |
| Week 1-2 | Easy (Boxes 6-13) | 8 | ğŸ“‹ Planned |
| Week 2-3 | Easy-Medium (Boxes 14-20) | 7 | ğŸ“‹ Planned |
| **Total** | **20 boxes** | **20** | **68% coverage** |

---

## Success Metrics

### Coverage Goals
- **Start:** 22 boxes (29%)
- **After Tier 1:** 27 boxes (35%)
- **After Tier 2:** 35 boxes (45%)
- **After Tier 3:** 52 boxes (68%)

### Quality Metrics
- All tests pass: 100%
- Build time: < 5 minutes
- Coverage percentage: > 90%
- Security issues: 0 critical
- Compliance score: 100%

### Frequency
- **Daily:** Standup, Daily Report, Code Freeze
- **Per test run:** All 20 boxes
- **Weekly:** Retrospective, Metrics Summary
- **Monthly:** Release planning

---

## Quick Start Scripts to Create

```bash
scripts/
â”œâ”€â”€ enhanced-test.sh              # Master test runner with all 20 boxes
â”œâ”€â”€ phase-1-trivial.sh           # Boxes 1-5
â”œâ”€â”€ phase-2-easy.sh              # Boxes 6-13
â”œâ”€â”€ phase-3-easy-medium.sh       # Boxes 14-20
â”œâ”€â”€ validate-compliance.sh        # Box #11
â”œâ”€â”€ generate-demo-script.sh       # Box #9
â”œâ”€â”€ create-release-candidate.sh   # Box #5
â”œâ”€â”€ generate-daily-report.sh      # Box #3
â”œâ”€â”€ generate-retrospective.sh     # Box #7
â”œâ”€â”€ generate-perf-report.sh       # Box #16
â”œâ”€â”€ generate-security-report.sh   # Box #18
â””â”€â”€ daily-standup.sh             # Box #1
```

---

## Benefits

1. **Immediate Wins:** Trivial boxes add 23% more coverage
2. **Build Confidence:** Easy boxes add 18% more coverage
3. **Exercise Full Pipeline:** Easy-medium boxes add 27% more coverage
4. **Regular Automation:** Every test run hits 52 boxes instead of 22
5. **Visible Progress:** Reports show exactly what's working
6. **Quick Feedback:** Trivial boxes take < 1 hour to implement per box

---

## Risk Mitigation

- **Risk:** Scripts fail in production
  - **Mitigation:** Test each script with `--dry-run` first

- **Risk:** Too many boxes to implement at once
  - **Mitigation:** Tier-based approach (5-8-7 per week)

- **Risk:** Scripts conflict with existing processes
  - **Mitigation:** Run in isolation, check for side effects

- **Risk:** Metrics collection slows tests
  - **Mitigation:** Run metrics in parallel where possible

---

## Success Example

After implementing all 20 boxes, a single test run would look like:

```
ğŸš€ EXPANDED AGENTIC SDLC TEST RUN
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“‹ Code Freeze & Standup
   âœ… Daily Standup: Completed
   âœ… Code Freeze: Initiated

ğŸ”¨ Development & Build
   âœ… Frontend Scaffold: 11 templates
   âœ… Backend Scaffold: 18 templates
   âœ… TypeScript Build: 0 errors
   âœ… Unit Tests: 421 passing

ğŸ§ª Enhanced Testing
   âœ… E2E Tests: 100% passing
   âœ… Code Quality: ESLint 0 issues
   âœ… Performance: Bundle 46KB gzipped
   âœ… Security: 0 critical issues

ğŸ“Š Reporting
   âœ… Compliance: 100% Zyp policies
   âœ… Metrics: 92% coverage, 100% tests
   âœ… Demo Script: Ready
   âœ… Release Candidate: Generated

âœ… COMPLETION
   âœ… Retrospective: Generated
   âœ… Daily Report: Created
   âœ… Next Sprint Prep: Ready

COVERAGE: 52/77 BOXES (68%)
TIME: 5 minutes 24 seconds
```

---

## Next Actions

1. **This Week:** Implement Tier 1 (5 boxes) â† START HERE
2. **Next Week:** Implement Tier 2 (8 boxes)
3. **Week After:** Implement Tier 3 (7 boxes)
4. **Ongoing:** Run enhanced test every day with all 20 boxes

Total implementation effort: ~20-25 hours spread over 3 weeks = ~5 hours/week