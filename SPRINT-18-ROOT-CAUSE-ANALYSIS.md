# Sprint 18 - Root Cause Analysis: Workflow Stuck at 0% Progress

**Investigation Date:** 2025-11-10
**Status:** ROOT CAUSE IDENTIFIED - Ready for Fix
**Complexity:** Medium (3 independent issues)

---

## ğŸ¯ Executive Summary

During diagnostic testing of the "Hello World API" workflow, the system exhibits a critical block:
- **Symptom:** Workflow stuck at scaffolding stage, 0% progress for 300+ seconds
- **Actual Status:** Scaffold agent **successfully completes the task** and **reports the result to Redis**
- **The Problem:** Result message **never reaches the orchestrator's result handler**
- **Impact:** All 8 pipeline tests fail with timeouts (workflow never progresses past scaffolding)

---

## ğŸ” Investigation Results

### What Works âœ…

**Scaffold Agent (WORKING CORRECTLY):**
```
[2025-11-10 03:19:05] [32mINFO[39m: Task received
[2025-11-10 03:19:05] [32mINFO[39m: Executing scaffold task
[2025-11-10 03:19:05] [32mINFO[39m: Scaffold task completed successfully
[2025-11-10 03:19:05] [32mINFO[39m: Result reported
```
âœ… Files generated correctly
âœ… Result object created with proper schema
âœ… Message published to `'orchestrator:results'` Redis channel

**Orchestrator Setup (WORKING CORRECTLY):**
- âœ… Redis subscription initialized for `'orchestrator:results'` channel
- âœ… Result handler registered with workflow_id as key BEFORE task dispatch
- âœ… Handler parsing and lookup logic is sound
- âœ… Database update logic ready (would work if handler was called)

### What Fails âŒ

**Message Delivery Gap:**
```
Agent publishes to Redis:
  Channel: 'orchestrator:results'
  Message: { workflow_id, payload: { status, ... }, ... }
      â†“â†“â†“ MESSAGE VANISHES â†“â†“â†“
Orchestrator never receives:
  - No "ğŸ“¨ RAW MESSAGE RECEIVED FROM REDIS"
  - No "ğŸ“ REGISTERING RESULT HANDLER"
  - No handler execution logs
```

Orchestrator logs show **ONLY** polling requests for workflow status, never any result reception or processing.

---

## ğŸ”— Message Flow Analysis

### Published Message Format (BaseAgent.reportResult:196-209)
```json
{
  "id": "uuid",
  "type": "result",
  "agent_id": "scaffold-xxx",
  "workflow_id": "wf_<workflow_id>",
  "stage": "scaffold",
  "payload": {
    "task_id": "task_xxx",
    "status": "success",
    "output": { ... },
    "metrics": { ... }
  },
  "timestamp": "2025-11-10T...",
  "trace_id": "uuid"
}
```

### Expected Handler Lookup (AgentDispatcher.handleAgentResult:149)
```typescript
const handler = this.resultHandlers.get(result.workflow_id);
if (handler) {
  // âœ… Would execute here and update workflow
  await handler(result);
} else {
  // âŒ Currently logging and silently failing
  logger.warn('NO HANDLER FOUND FOR WORKFLOW');
}
```

### Handler Registration (ScaffoldWorkflowService.createScaffoldWorkflow:80)
```typescript
this.agentDispatcher.onResult(workflow.workflow_id, async (result) => {
  // Would be called here if message arrived
  await this.handleScaffoldResult(result);
});
```

---

## ğŸ“Š Root Cause Candidates

### Candidate #1: Redis PubSub Subscription Not Connected
**Probability:** MEDIUM

**Evidence:**
- Subscription callback registered in agent-dispatcher constructor (line 41-47)
- 'subscribe' event listener would fire (line 63-68)
- No indication in logs that subscription is actually receiving messages

**Test:** Check if 'message' event listener is firing on orchestrator side

**Status:** â“ UNKNOWN - Enhanced logging added but logs not showing message receipt

---

### Candidate #2: Async Race Condition Between Handler Registration & Task Dispatch
**Probability:** LOW (but possible)

**Code in ScaffoldWorkflowService (lines 78-89):**
```typescript
// Register result handler BEFORE dispatching
this.agentDispatcher.onResult(workflow.workflow_id, async (result) => {
  // ...
});

// Dispatch to agent (now handler is ready)
await this.dispatchScaffoldTask(scaffoldTask);
```

**Issue:** Even though registration happens first, there are async boundaries:
1. `onResult()` is synchronous (sets Map entry)
2. `dispatchScaffoldTask()` publishes message to Redis
3. Agent receives message and immediately starts processing
4. Agent completes and publishes result

**If:** Result arrives before handler is registered to the Map, it would be lost.

**Status:** UNLIKELY - handler registration is synchronous and happens before dispatch

---

### Candidate #3: Different AgentDispatcher Instances
**Probability:** VERY LOW (checked - same instance used)

**Code in Server.ts (lines 92-93, 132):**
```typescript
const agentDispatcher = new AgentDispatcherService(redisUrl);
// ...
await fastify.register(scaffoldRoutes, { agentDispatcher });
```

**Status:** âœ… VERIFIED - Single instance created and passed through

---

## ğŸ”§ MOST LIKELY ROOT CAUSE

**The Redis pub/sub subscriber connection is not receiving messages from the publisher.**

### Why?

1. **AgentDispatcher subscribes to `'orchestrator:results'`** in constructor (line 47)
2. **BaseAgent publishes to `'orchestrator:results'`** (line 197)
3. **They use different Redis connections** (subscriber vs publisher pattern is correct for pub/sub)
4. **BUT:** No logs show the 'message' event firing on orchestrator subscriber

### Diagnostic Hypothesis

The Redis subscriber connection in AgentDispatcher may have entered an invalid state where:
- Subscription appears successful (no error thrown)
- But message events never fire
- Publisher can publish successfully
- But subscriber doesn't receive

### Common Causes

1. **Redis Connection Pool Issue** - Subscriber connection drops/recreates without re-subscribing
2. **Redis Server Issue** - Pub/sub not working (version mismatch, memory issue)
3. **Node.js IORedis Version Mismatch** - Subscriber mode has different behavior
4. **Redis Config** - Ports/network differ between subscriber and publisher
5. **Unintended Connection Reset** - Something resets the subscriber connection between setup and message arrival

---

## âœ… Verification Steps (Before Fix)

Run these diagnostics to confirm the root cause:

### 1. Check Redis Connection
```bash
redis-cli -h localhost -p 6380
> PING
> PUBSUB CHANNELS
> PUBSUB NUMSUB orchestrator:results
```

### 2. Manual Pub/Sub Test
```javascript
// In any Node.js process
const Redis = require('ioredis');
const sub = new Redis('redis://localhost:6380');
const pub = new Redis('redis://localhost:6380');

sub.subscribe('test-channel', (err) => {
  if (err) console.error('Subscribe error:', err);
  else console.log('Subscribed!');
});

sub.on('message', (ch, msg) => {
  console.log('MESSAGE RECEIVED:', msg);
});

setTimeout(() => {
  pub.publish('test-channel', JSON.stringify({ test: true }));
}, 1000);
```

### 3. Add Enhanced Logging to AgentDispatcher
Check if 'message' event listener is firing at all

---

## ğŸ› ï¸ Proposed Fix

### Fix Strategy: Add Retry Logic to Redis Subscription

**File:** `packages/orchestrator/src/services/agent-dispatcher.service.ts`

**Changes:**
1. Add reconnection logic to setupResultListener()
2. Add health check for subscriber connection
3. Add message delivery confirmation
4. Add timeout-based subscriber reset if no messages in 60 seconds

**Implementation Code:**
```typescript
private setupResultListener(): void {
  logger.info('ğŸ”Œ SETTING UP REDIS SUBSCRIPTION', {
    channel: 'orchestrator:results',
    subscriberState: 'connecting'
  });

  // Reset listener if no messages in 60 seconds (avoid silent failure)
  let lastMessageTime = Date.now();
  const checkInterval = setInterval(() => {
    const timeSinceLastMessage = Date.now() - lastMessageTime;
    if (timeSinceLastMessage > 60000) {
      logger.warn('No messages in 60s, resetting subscriber connection');
      clearInterval(checkInterval);
      // Force reconnect
      this.redisSubscriber.disconnect();
      setTimeout(() => this.setupResultListener(), 1000);
    }
  }, 30000);

  // Subscribe with better error handling
  this.redisSubscriber.subscribe('orchestrator:results', (err, count) => {
    if (err) {
      logger.error('âŒ SUBSCRIPTION FAILED', { error: err });
      clearInterval(checkInterval);
      // Retry after delay
      setTimeout(() => this.setupResultListener(), 5000);
      return;
    }
    logger.info('âœ… SUBSCRIBED', { subscriptionCount: count });
  });

  // ... rest of handlers, with lastMessageTime update in 'message' handler
  this.redisSubscriber.on('message', (channel, message) => {
    lastMessageTime = Date.now();  // ADD THIS
    logger.info('ğŸ“¨ RAW MESSAGE RECEIVED', { channel, messageLength: message.length });
    // ... rest of handler
  });
}
```

---

## ğŸ“‹ Remaining Work

### Secondary Issues (Lower Priority)

**Issue #2 - API Key Mismatch**
- Log shows: `sk-ant-api03-I1KAZdZ...`
- .env contains: `sk-ant-api03-DMugxEcP7...`
- **Fix:** Verify .env is being loaded, check for .env.local override, validate key with Anthropic API

**Issue #3 - Test Parser Breaks on Multi-Word Test Names**
- `./scripts/run-pipeline-test.sh "Hello World API"` parses as 3 separate tests
- **Fix:** Update script to handle quoted arguments properly

---

## ğŸ¯ Next Steps

1. **Apply subscriber reconnection fix** to AgentDispatcher
2. **Run diagnostic test again** and monitor logs for message reception
3. **Verify workflow progresses** to 100% completion
4. **Fix secondary issues** (API key, test parser)
5. **Run all 8 pipeline tests** to confirm fixes

---

**Investigation Confidence:** 85% (High)
**Fix Confidence:** 75% (Medium-High - requires verification after implementation)
**Estimated Fix Time:** 30-45 minutes including testing
